#!/bin/bash

APPLICATION=$1
LOCATION="us-east4-a"
CLUSTER=qitransientcluster
REG_SERVER=gcr.io/${RESOURCES}

function GetPlatformContainer()
{
    # Use the Prebuilt gcloud sdk container provided by Google.
    docker pull google/cloud-sdk
}

GetPlatformContainer

# Login with the container. This currently requires user interaction
# at the browser to complete. The below command creates a volume
# at the ${CONFIG_MOUNT} location in order to persist kubernetes
# login credentials by setting the KUBECONFIG environment variable.
#
function Login()
{
    docker run \
        -it \
        --name ${CONTAINER_NAME} \
        -e KUBECONFIG=${CONFIG_MOUNT}/kube_config \
        --mount type=volume,target=${CONFIG_MOUNT} \
        google/cloud-sdk \
        gcloud auth login
}

Login

# Common docker command component for gcloud and kubectl commands inside
# of the google/cloud-sdk container.
#
PREFIX="docker run \
    --rm \
    -e KUBECONFIG=${CONFIG_MOUNT}/kube_config \
    --volumes-from ${CONTAINER_NAME} \
    google/cloud-sdk"

GCLOUD="$PREFIX gcloud"
KUBECTL="$PREFIX kubectl"

function Provision()
{
    # Create a hosting project for transient resources.
    $GCLOUD projects create $RESOURCES

    $GCLOUD config set project $RESOURCES
    $GCLOUD config set compute/zone $LOCATION

    # GCP requires setting up billing on a project before certain services
    # can be used. GCP does not automatically create a link to billing
    # as the billing structure of GCP allows for many billing accounts within
    # an organization.
    echo
    echo CHOOSE A BILLING ACCOUNT TO LINK WITH "\"${RESOURCES}\""

    # Create a menu for billing account options.
    let option_id=0
    accounts=()
    while IFS= read -r line; do
        let option_id++

        # Provide an options menu to select a billing account.
        echo "[${option_id}] ${line}"
        account_id="${line%% *}"
        accounts+=("$account_id")

    # Lists all of the available billing accounts for the current user
    # formatted to list the account number and the display name.
    #
    done < <(docker run \
        --rm \
        -e KUBECONFIG=${CONFIG_MOUNT}/kube_config \
        --volumes-from ${CONTAINER_NAME} \
        google/cloud-sdk \
        gcloud beta billing accounts list \
        --format "table[no-heading](name,displayName)")

    echo
    read -n 1 -p "> " CHOICE
    echo

    let CHOICE--

    $GCLOUD alpha billing projects link $RESOURCES --billing-account ${accounts[CHOICE]}

    # Enable the use of the container and the container registry APIs for project
    $GCLOUD services enable containerregistry.googleapis.com
    $GCLOUD services enable container.googleapis.com
}

Provision

function PrepareDocker()
{
    # Add authentication information for docker to login to gcr.io
    $GCLOUD auth configure-docker --project $RESOURCES

    # Login to gcr.io
    $GCLOUD auth print-access-token | docker login \
        -u oauth2accesstoken \
        --password-stdin https://gcr.io
}

PrepareDocker

REMOTE_IMAGE=$(PushToRemote ${APPLICATION} ${REG_SERVER})

function Deploy()
{
    local _address="${APPLICATION}-${RESOURCES}"
    local _compute_tag="cloud-notes-server"

    $GCLOUD compute addresses create ${_address} \
        --region us-east4

    $GCLOUD compute instances create \
        $APPLICATION                      \
        --machine-type n1-standard-1      \
        --zone ${LOCATION}                \
        --image-family ubuntu-1804-lts    \
        --image-project ubuntu-os-cloud   \
        --address ${_address}             \
        --tags ${_compute_tag}            \
        --meta-data startup-script='#!/bin/bash
        echo "Checking for CUDA and installing."
        # Check for CUDA and try to install.
        if ! dpkg-query -W cuda-10-0; then
            curl -O \
                http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb
            dpkg -i ./cuda-repo-ubuntu1804_10.0.130-1_amd64.deb
            apt-key adv \
                --fetch-keys \
                http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub
            apt-get update
            apt-get install cuda-10-0 -y
        fi
        # Enable persistence mode
        nvidia-smi -pm 1
        # Check for docker
        if ! dpkg-query -W docker-ce; then
            apt-get install \
                apt-transport-https \
                ca-certificates \
                gnupg-agent \
                software-properties-common
            curl -O https://download.docker.com/linux/linux/ubuntu/gpg | apt-key add -
            apt-add-repository \
                "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
                $(lsb_release -cs) \
                stable"
            apt-get update
            apt-get install -y \
                docker-ce \
                docker-ce-cli \
                containerd.io
        fi'


    # TODO:
    # Attach accelerator to image and duplicate the following container
    # deployment parameters in non container optimized os deployment
    # from above..
    #--accelerator nvidia-tesla-p4 \
    #--container-image ${REMOTE_IMAGE} \
    #--container-privileged            \
    #--container-restart-policy always \

    $GCLOUD compute firewall-rules create allow-cn-server \
        --allow tcp:8888 --target-tags ${_compute_tag}

    # TODO:
    # Attach/Mount data to VM and share the mount with the container
    # being deployed above.

    JUPYTER_SERVER="${_address}"

}

Deploy

function ConnectToServer()
{
    JUPYTER_POD=$($KUBECTL \
        get pods \
        -o=custom-columns=NAME:.metadata.name \
        --no-headers)

    $KUBECTL logs -f $JUPYTER_POD
}

# Given a source directory, copies its contents to a GCP bucket
#
# ARGUMENTS:
#   _SOURCE_DIR  - The local machine source to copy
#   _BUCKET_NAME - The GCP Data Bucket to upload data
#   _AUTH_CONFIG - The pre-authenticated config container
#
function CopyData()
{
    _SOURCE_DIR=$1
    _BUCKET_NAME=$2
    _AUTH_CONFIG=$3

    docker run \
        --rm \
        --mount type=bind,source="${_SOURCE_DIR}",target=/mnt/data \
        --volumes-from ${_AUTH_CONFIG} \
        google/cloud-sdk \
        gsutil -m \
            cp -r /mnt/data/* gs://${_BUCKET_NAME}
}
