#!/bin/bash

CONTAINER_NAME=$1
CONFIG_MOUNT=$2
APPLICATION=$3
RESOURCES=$4
DATASOURCE=$5

LOCATION="us-east4-a"
CLUSTER=qitransientcluster
REG_SERVER=gcr.io/${RESOURCES}

function GetPlatformContainer()
{
    # Use the Prebuilt gcloud sdk container provided by Google.
    docker pull google/cloud-sdk
}

GetPlatformContainer

# Login with the container. This currently requires user interaction
# at the browser to complete. The below command creates a volume
# at the ${CONFIG_MOUNT} location in order to persist kubernetes
# login credentials by setting the KUBECONFIG environment variable.
#
function Login()
{
    local _container_name=$1
    local _config_mount=$2

    docker run \
        -it \
        --name ${_container_name} \
        --label qi_container_type=login-config \
        -e KUBECONFIG=${_config_mount}/kube_config \
        --mount type=volume,target=${_config_mount} \
        --mount type=bind,source="$(dirname `GetAbsPath ${BASH_SOURCE[0]}`)/scripts",target=/mnt/startup \
        google/cloud-sdk \
        gcloud auth login
}

Login $CONTAINER_NAME $CONFIG_MOUNT

# Common docker command component for gcloud and kubectl commands inside
# of the google/cloud-sdk container.
#
PREFIX="docker run \
    --rm \
    -e KUBECONFIG=${CONFIG_MOUNT}/kube_config \
    --volumes-from ${CONTAINER_NAME} \
    google/cloud-sdk"

GCLOUD="$PREFIX gcloud"
KUBECTL="$PREFIX kubectl"

function Provision()
{
    local _resources=$1
    local _location=$2

    # Create a hosting project for transient resources.
    $GCLOUD projects create $_resources

    $GCLOUD config set project $_resources
    $GCLOUD config set compute/zone $_location

    # GCP requires setting up billing on a project before certain services
    # can be used. GCP does not automatically create a link to billing
    # as the billing structure of GCP allows for many billing accounts within
    # an organization.
    echo
    echo CHOOSE A BILLING ACCOUNT TO LINK WITH "\"${_resources}\""

    # Create a menu for billing account options.
    let option_id=0
    accounts=()
    while IFS= read -r line; do
        let option_id++

        # Provide an options menu to select a billing account.
        echo "[${option_id}] ${line}"
        account_id="${line%% *}"
        accounts+=("$account_id")

    # Lists all of the available billing accounts for the current user
    # formatted to list the account number and the display name.
    #
    done < <(docker run \
        --rm \
        -e KUBECONFIG=${CONFIG_MOUNT}/kube_config \
        --volumes-from ${CONTAINER_NAME} \
        google/cloud-sdk \
        gcloud beta billing accounts list \
        --format "table[no-heading](name,displayName)")

    echo
    read -n 1 -p "> " CHOICE
    echo

    let CHOICE--

    $GCLOUD alpha billing projects link $_resources --billing-account ${accounts[CHOICE]}

    # Enable the use of the container and the container registry APIs for project
    $GCLOUD services enable containerregistry.googleapis.com
    $GCLOUD services enable container.googleapis.com
}

Provision $RESOURCES $LOCATION

function PrepareDocker()
{
    # Login to gcr.io
    $GCLOUD auth print-access-token | docker login \
        -u oauth2accesstoken \
        --password-stdin https://gcr.io
}

PrepareDocker

REMOTE_IMAGE=$(PushToRemote ${APPLICATION} ${REG_SERVER})

function Deploy()
{
    local _address="${APPLICATION}-${RESOURCES}"
    local _compute_tag="cloud-notes-server"

    $GCLOUD compute addresses create ${_address} \
        --region us-east4

    # Automatically stop this resource (GPU cost is high).
    $GCLOUD compute instances create \
        $APPLICATION                               \
        --zone ${LOCATION}                         \
        --accelerator type=nvidia-tesla-p4,count=1 \
        --custom-cpu 8                             \
        --custom-memory 32GB                       \
        --maintenance-policy TERMINATE             \
        --restart-on-failure                       \
        --image-family ubuntu-1804-lts             \
        --image-project ubuntu-os-cloud            \
        --boot-disk-size 200GB                     \
        --address ${_address}                      \
        --tags ${_compute_tag}                     \
        --metadata \
        __qi_container_name="$REMOTE_IMAGE",__qi_app_bucket=<DATA_SOURCE> \
        --metadata-from-file startup-script=/mnt/startup/ubuntu-startup.sh
 
    $GCLOUD compute firewall-rules create allow-cn-server \
        --allow tcp:8888 --target-tags ${_compute_tag}

    # TODO:
    # Use Cloud Function to create a callback on startup-script
    # completion?

    JUPYTER_SERVER=$($GCLOUD \
        compute addresses describe \
        ${_address} \
        --region us-east4 \
        --format "table[no-heading](address)")
}

Deploy

function ConnectToServer()
{
    JUPYTER_POD=$($KUBECTL \
        get pods \
        -o=custom-columns=NAME:.metadata.name \
        --no-headers)

    $KUBECTL logs -f $JUPYTER_POD
}

# Given a source directory, copies its contents to a GCP bucket
#
# ARGUMENTS:
#   _SOURCE_DIR  - The local machine source to copy
#   _BUCKET_NAME - The GCP Data Bucket to upload data
#   _AUTH_CONFIG - The pre-authenticated config container
#
function CopyData()
{
    _SOURCE_DIR=$1
    _BUCKET_NAME=$2
    _AUTH_CONFIG=$3

    docker run \
        --rm \
        --mount type=bind,source="${_SOURCE_DIR}",target=/mnt/data \
        --volumes-from ${_AUTH_CONFIG} \
        google/cloud-sdk \
        gsutil -m \
            cp -r /mnt/data/* gs://${_BUCKET_NAME}
}
